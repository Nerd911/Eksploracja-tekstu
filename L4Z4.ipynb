{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict as dd\n",
    "from typing import List, Dict, Set\n",
    "import nltk\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "import pickle\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_set():\n",
    "    all_lemmas = set()\n",
    "    for line in open('Dane/polimorfologik-2.1.txt', encoding='utf-8'):\n",
    "        L = line.split(';')[1].lower()\n",
    "        all_lemmas.add(L)\n",
    "    return all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal_form(w):\n",
    "    polish_map = {\n",
    "        \"ż\": \"z\",\n",
    "        \"ź\": \"z\",\n",
    "        \"x\": \"z\",\n",
    "        \"ó\": \"o\",\n",
    "        \"ł\": \"l\",\n",
    "        \"ć\": \"c\",\n",
    "        \"ą\": \"a\",\n",
    "        \"ń\": \"n\",\n",
    "        \"ę\": \"e\",\n",
    "    }\n",
    "    ortographic_map = {\n",
    "        \"u\": \"o\",\n",
    "        \"om\": \"a\",\n",
    "        \"en\": \"e\",\n",
    "        \"em\": \"e\",\n",
    "        \"on\": \"a\",\n",
    "        \"rz\": \"e\",\n",
    "#         \"fk\": \"wk\",\n",
    "#         \"af\": \"aw\",\n",
    "        \"f\": \"w\",\n",
    "        \"sz\": \"z\",\n",
    "    }\n",
    "    tmp = \"\"\n",
    "    for c in w:\n",
    "        tmp += c if c not in polish_map else polish_map[c]\n",
    "    l = len(w)\n",
    "    res = \"\"\n",
    "    i = 0\n",
    "    while i < l:\n",
    "        if i < l - 1 and tmp[i:(i+2)] in ortographic_map:\n",
    "            res += ortographic_map[tmp[i:(i+2)]]\n",
    "            i += 2\n",
    "            continue\n",
    "        if tmp[i] in ortographic_map:\n",
    "            res += ortographic_map[tmp[i]]\n",
    "            i += 1\n",
    "            continue\n",
    "        res += tmp[i]\n",
    "        i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionaries():\n",
    "    ws = load_word_set()\n",
    "    res1 = dd(list)\n",
    "    res2 = dd(list)\n",
    "    for w in word_set:\n",
    "        norm_w = get_normal_form(w)\n",
    "        res1[norm_w].append(w)\n",
    "        res2[w[0]].append(w)\n",
    "    return res1, res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin(l):\n",
    "    res = None\n",
    "    for i, el in enumerate(l):\n",
    "        if res is None or el < l[res]:\n",
    "            res = i\n",
    "    return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(w, words):\n",
    "    edit_distances = [levenshtein(w, w1) for w1 in words]\n",
    "    return words[argmin(edit_distances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_word(w, norm_dicts):\n",
    "    d1, d2 = norm_dicts\n",
    "    norm_w = get_normal_form(w)\n",
    "    if norm_w in d1:\n",
    "        return find_closest(w, d1[norm_w])\n",
    "    w_candidates = d2[w[0]][:]\n",
    "    if len(w) > 1:\n",
    "        w_candidates += d2[w[1]]\n",
    "    return find_closest(w, w_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = load_word_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lokomotywa: lokomotywa\n",
      "lokomotywa: kolorowa\n",
      "lokomotywa: lokomotywa\n",
      "lokomotywa: kolorowa\n",
      "lokomotywa: lokowała\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdopodobieństwo: prawdopodobieństwo\n",
      "prawdomówny: prawdomówno\n",
      "prawdomówny: prawdomówny\n",
      "prawdomówny: przodowny\n",
      "komputerek: kompaturek\n",
      "komputerek: komputerem\n",
      "komputerek: komputerek\n",
      "komputerek: korektorek\n",
      "komputerek: kompaturek\n",
      "dziewczyna: dziewczyna\n",
      "dziewczyna: dziewczyna\n",
      "dziewczyna: dziewczyna\n",
      "dziewczyna: dziewczyna\n",
      "dziewczyna: dziewczyna\n",
      "dziewczyna: dziewczyna\n",
      "dziewczyna: dziewczyna\n",
      "dziewczyna: dziewczyn\n",
      "dziewczyna: dziewczyn\n",
      "przyjaźń: przyjada\n",
      "przyjaźń: przyjaźń\n",
      "przyjaźń: przyjaźń\n",
      "przyjaźń: przyjaźń\n",
      "przyjaźń: przyjaźń\n",
      "niszczyciel: niszczyciel\n",
      "niszczyciel: niszczyciel\n",
      "niszczyciel: niszczycie\n",
      "niszczyciel: niszczyciel\n",
      "niszczyciel: niszczyciel\n"
     ]
    }
   ],
   "source": [
    "d1, d2 = get_dictionaries()\n",
    "with open(\"Dane/literowki1.txt\", \"r\") as ifile:\n",
    "    for line in ifile:\n",
    "        line = nltk.word_tokenize(line)\n",
    "        correct, incorrect = line[0], line[1]\n",
    "        print(f\"{line[0]}: {correct_word(line[1], (d1, d2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
