{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict as dd\n",
    "from itertools import chain\n",
    "from collections import namedtuple\n",
    "\n",
    "import os\n",
    "os.chdir(r'C:\\Users\\Michal\\Documents\\Studia\\eksploracja_tekstow')\n",
    "import pickle\n",
    "import shelve\n",
    "import unicodedata\n",
    "\n",
    "import time\n",
    "from termcolor import colored\n",
    "\n",
    "from tqdm import trange, tqdm, tqdm_notebook\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Article = namedtuple(\"Article\", [\"title\", \"header\", \"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = set()\n",
    "# for line in open(\"dane\\stop_words.txt\", 'r', encoding='utf8'):\n",
    "#     stop_words.add(line[:-1])\n",
    "# punctuation = set([\"'\", \"(\", \")\", \"-\", \"!\", \"[\", \"]\", \"–\", \"\", \"&\", \"?\", \"''\", \":\", ';', '``', '.', '``', '„', '”', ','])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec = dd(list)\n",
    "# for line in open(r'dane\\wiki-forms-all-100-cbow-hs.txt', 'r', encoding='utf8'):\n",
    "#     line = line[:-1].split(' ')\n",
    "#     if len(line) != 101:\n",
    "#         continue\n",
    "#     word = line[0].lower()\n",
    "#     embs = [float(val) for val in line[1:]]\n",
    "#     word2vec[word] = embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('.cache'):\n",
    "#     os.makedirs('.cache')\n",
    "    \n",
    "# with open(f'.cache/word2vec.pickle', 'wb') as file:\n",
    "#     pickle.dump(word2vec, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(f'.cache/word2vec.pickle', 'rb') as file:\n",
    "    word2vec = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'dane\\fp_wiki.txt', 'r', encoding='utf8') as f:\n",
    "#     wikipedia_raw = f.read()\n",
    "# articles_raw = wikipedia_raw.split('\\n\\n')\n",
    "\n",
    "# wikipedia_db = []\n",
    "# for article_raw in tqdm(articles_raw):\n",
    "#     article_lines = article_raw.split('\\n')\n",
    "\n",
    "#     if len(article_lines) < 2:\n",
    "#         continue\n",
    "\n",
    "#     title = article_lines[0][7:]\n",
    "#     header = article_lines[1]\n",
    "#     content = '\\n'.join(article_lines[2:])\n",
    "#     if len(content) == 0:\n",
    "#         continue\n",
    "\n",
    "#     article = Article(title, header, content)\n",
    "#     wikipedia_db.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('.cache'):\n",
    "#     os.makedirs('.cache')\n",
    "    \n",
    "# with open(f'.cache/wikipedia.pickle', 'wb') as file:\n",
    "#     pickle.dump(wikipedia_db, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(f'.cache/wikipedia.pickle', 'rb') as file:\n",
    "    wikipedia_db = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ee53d31af8740e387be6ca4f38ef2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1159857), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "title_list_raw = []\n",
    "for article in tqdm_notebook(wikipedia_db):\n",
    "    title_list_raw.append(article.title)\n",
    "title_list = [x.lower().replace(\" \",\"\") for x in title_list_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2433fe4944034195889fe908e268607b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1159857), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# short_wiki = []\n",
    "# for art in tqdm_notebook(wikipedia_db):\n",
    "#     good_words = []\n",
    "    \n",
    "#     title = nltk.word_tokenize(art.title)\n",
    "#     for word in title:\n",
    "#         word = word.lower()\n",
    "#         if word in stop_words or word in punctuation:\n",
    "#             continue\n",
    "#         good_words.append(word)\n",
    "        \n",
    "#     content = nltk.word_tokenize(art.content)\n",
    "#     for word in content[:100]:\n",
    "#         word = word.lower()\n",
    "#         if word in stop_words or word in punctuation:\n",
    "#             continue\n",
    "#         good_words.append(word)\n",
    "        \n",
    "#     short_article = (good_words)[:50]\n",
    "#     short_wiki.append(short_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('.cache'):\n",
    "#     os.makedirs('.cache')\n",
    "    \n",
    "# with open(f'.cache/short_wiki.pickle', 'wb') as file:\n",
    "#     pickle.dump(short_wiki, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(f'.cache/short_wiki.pickle', 'rb') as file:\n",
    "    short_wiki = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486eb9c0160c4971962d3b3239aeb2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1159857), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# wiki_embs = []\n",
    "# for i, art in enumerate(tqdm_notebook(short_wiki)):\n",
    "#     art_emb = np.zeros(100)\n",
    "#     for word in art:\n",
    "#         word = word.lower()\n",
    "#         if word2vec[word] == []:\n",
    "#             continue\n",
    "#         emb = np.array(word2vec[word])\n",
    "#         art_emb += emb\n",
    "#     wiki_embs.append((i, art_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists('.cache'):\n",
    "#     os.makedirs('.cache')\n",
    "    \n",
    "# with open(f'.cache/wiki_embs.pickle', 'wb') as file:\n",
    "#     pickle.dump(wiki_embs, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(f'.cache/wiki_embs.pickle', 'rb') as file:\n",
    "    wiki_embs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1159857, 1159857, 1159857)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_embs), len(short_wiki), len(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit([w[1] for w in wiki_embs], [w[0] for w in wiki_embs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(sentence, n=2):\n",
    "    ngram = []\n",
    "    for it in range(len(sentence) - n + 1):\n",
    "        ngram.append(sentence[it : it + n])\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_search(q, bdr=5, n=2):\n",
    "    query = q.lower().replace(\" \",\"\")\n",
    "    query_len = len(query)\n",
    "    \n",
    "    grams = get_ngrams(query, n)\n",
    "    \n",
    "    candidates_long = [x for x in title_list if (len(x) >= (query_len - bdr) and len(x) <= (query_len + bdr))]\n",
    "\n",
    "    final_score = []\n",
    "    for title in candidates_long:\n",
    "        title_score = 0\n",
    "        for gram in grams:\n",
    "            if gram in title:\n",
    "                title_score += 1\n",
    "        final_score.append(title_score)\n",
    "    \n",
    "    max_val = final_score[np.argmax(final_score)]\n",
    "    best_fits = [i for i, x in enumerate(final_score) if x == max_val]\n",
    "    \n",
    "    if len(best_fits) > 1:\n",
    "        best_titles =  sorted([(candidates_long[i], i) for i in best_fits], key=lambda x: len(x[0]))\n",
    "        best_trimmed = [(title[: title.find('(')], i) for title, i in best_titles]\n",
    "        \n",
    "        init_len = len(best_trimmed[0][0])\n",
    "        i = 1\n",
    "        while i < len(best_trimmed) and len(best_trimmed[i][0]) == init_len:\n",
    "            i += 1\n",
    "        \n",
    "        if i > 1:\n",
    "            best_earliest = sorted(best_trimmed[:i], key=lambda x: x[1])\n",
    "            best_fits = [best_earliest[0][1]]\n",
    "            \n",
    "            j = 1\n",
    "            while j < i and best_earliest[j][0] == best_earliest[j-1][0]:\n",
    "                j += 1\n",
    "            i = j\n",
    "            \n",
    "        best_fits = [i for _, i in best_trimmed[:i]]\n",
    "    best_fits = [title_list.index(np.array(candidates_long)[i]) for i in best_fits]\n",
    "    \n",
    "    return best_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_similar(query, n_display=5):\n",
    "    i = title_search(query)[0]\n",
    "    emb = wiki_embs[i][1]\n",
    "    \n",
    "    print(f'QUERY: {query}\\n')\n",
    "    for i in knn.kneighbors(emb.reshape(1,-1), return_distance=False)[0][:n_display]:\n",
    "        art = wikipedia_db[i]\n",
    "        print(art.title + '\\n')\n",
    "        print(art.content + '\\n')\n",
    "        print('-' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: właasadcapierccienai\n",
      "\n",
      "Władca Pierścieni\n",
      "\n",
      "Władca Pierścieni ( ang . `` The Lord of the Rings '' ) – powieść `` high fantasy '' J.R.R . Tolkiena , której akcja rozgrywa się w mitologicznym świecie Śródziemia .\n",
      "Jest ona kontynuacją innej powieści tego autora zatytułowanej `` Hobbit , czyli tam i z powrotem '' .\n",
      "`` Władca Pierścieni '' jest często mylnie nazywany trylogią , choć w rzeczywistości jest to powieściowa całość , podzielona na sześć ksiąg . Ze względu na swoją dużą objętość została wydana w trzech tomach z powodu nacisków wydawcy ; nie było to jednak oryginalne zamierzenie Tolkiena . Powieść składa się z sześciu części:\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dwie wieże\n",
      "\n",
      "Dwie wieże ( ang . `` The Two Towers '' ) – drugi tom powieści ( błędnie nazywanej trylogią ) pt . `` Władca Pierścieni '' autorstwa J.R.R . Tolkiena . Tom ten obejmuje księgę trzecią ( `` Zdrada Isengardu '' ) i czwartą ( `` Podróż do Mordoru '' ) powieści , a został po raz pierwszy wydany 11 listopada 1954 roku w Wielkiej Brytanii .\n",
      "`` Władca Pierścieni '' składa się z sześciu „ksiąg” poza wstępem , prologiem oraz rozszerzeniami . Powojenne braki papieru wymusiły na wydawcy opublikowanie powieści w trzech oddzielnych tomach . Akcja `` Dwóch wież '' obejmuje księgi trzecią oraz czwartą .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Książę Chaosu\n",
      "\n",
      "Książę Chaosu ( ang . `` Prince of Chaos '' ) – dziesiąta i ostatnia ( nie licząc krótkich opowiadań ) część cyklu fantasy `` Kroniki Amberu '' ( The Chronicles of Amber ) Rogera Zelaznego . Jest to zarazem piąta część drugiej części cyklu , tzw . `` Kronik Merlina '' .\n",
      "Wydanie angielskie ( ) opublikowano w USA w listopadzie 1991 przez wydawnictwo `` William Morrow and Company '' . Okładkę zaprojektowała Linda Burr . Wydanie liczy 225 stron .\n",
      "Pierwsze polskie wydanie ukazało się w 1995 r. nakładem wydawnictwa `` Iskry '' ( Warszawa , ) , w tłumaczeniu Piotra W. Cholewy , ilustrację na okładce wykonał Janusz Gutkowski , redaktorem była Małgorzata Pogoda , a redaktorem technicznym Elżbieta Kozak .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Herkules i zaginione królestwo\n",
      "\n",
      "Herkules i zaginione królestwo ( ang . `` Hercules and the Lost Kingdom '' ) – amerykańsko-nowozelandzki telewizyjny film przygodowy z 1994 roku .\n",
      "Film ten należy do cyklu telewizyjnych filmów przygodowych swobodnie nawiązujących do postaci Herkulesa ( Heraklesa ) z mitologii greckiej , w których główną rolę grał Kevin Sorbo . Filmy te dały z kolei początek serialowi `` Herkules '' ( `` The Legendary Journeys '' , 1995-99 ) .\n",
      "Herkules , syn Zeusa , stacza zwycięską walkę z olbrzymem Garganem . Zaraz po walce przybywa do niego posłaniec z prośbą o uwolnienie legendarnego miasta Troi , od klątwy rzuconej przez złą boginię Hery . Herkules wyrusza na ratunek mieszkańcom przeklętego miasta . Podczas wędrówki ratuję piękną Dejanirę , którą wieśniacy chcą złożyć bogom w ofierze . Ona wierząc , że on jest jej przeznaczony , postanawia towarzyszyć mu w dalszej podróży . Wkrótce docierają do Troi ...\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Rycerz cieni\n",
      "\n",
      "Rycerz Cieni ( ang . `` Knight of Shadows '' ) – dziewiąta część cyklu fantasy Kroniki Amberu ( The Chronicles of Amber ) Rogera Zelaznego . Jest to zarazem czwarta część drugiej części cyklu , tzw . `` Kronik Merlina '' .\n",
      "Wydanie angielskie ( ) opublikowano w USA w listopadzie 1989 przez wydawnictwo `` William Morrow and Company '' . Okładkę zaprojektowała Linda Burr . Wydanie liczy 215 stron .\n",
      "Pierwsze polskie wydanie ukazało się w 1995 r. nakładem wydawnictwa `` Iskry '' ( Warszawa , ) , w tłumaczeniu Piotra W. Cholewy .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_similar('właasadcapierccienai', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
